{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0ce39260-a282-4fd3-b8c7-f467afd96ad5",
   "metadata": {},
   "source": [
    "Ensure you have a benchmark, e.g. ./benchmark/ClinVarBenchmark_PB_202504.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b88032e7-83b3-4f0c-bacc-af4c3491d869",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: biopython in c:\\users\\lxsbx\\anaconda3\\lib\\site-packages (1.85)\n",
      "Requirement already satisfied: numpy in c:\\users\\lxsbx\\anaconda3\\lib\\site-packages (from biopython) (2.1.3)\n"
     ]
    }
   ],
   "source": [
    "!pip install biopython"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f866ca37-5dec-4f4d-a564-022d7ceadb32",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import subprocess\n",
    "from tqdm import tqdm\n",
    "import glob\n",
    "from Bio import Entrez, SeqIO\n",
    "import xml.etree.ElementTree as ET\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8ce2c502-64ef-410e-852a-3806ab51095a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading gene2accession.gz ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import requests\n",
    "import gzip\n",
    "import shutil\n",
    "import urllib.request\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# 1. Create directories\n",
    "os.makedirs(\"benchmark\", exist_ok=True)\n",
    "os.makedirs(\"protein_dataset\", exist_ok=True)\n",
    "\n",
    "# 2. Download gene2accession.gz\n",
    "gene2accession_url = \"https://ftp.ncbi.nlm.nih.gov/gene/DATA/gene2accession.gz\"\n",
    "gene2accession_gz = \"protein_dataset/gene2accession.gz\"\n",
    "gene2accession_file = \"protein_dataset/gene2accession\"\n",
    "\n",
    "print(\"Downloading gene2accession.gz ...\")\n",
    "r = requests.get(gene2accession_url, stream=True)\n",
    "with open(gene2accession_gz, \"wb\") as f:\n",
    "    shutil.copyfileobj(r.raw, f)\n",
    "\n",
    "# Unzip\n",
    "print(\"Unzipping gene2accession.gz ...\")\n",
    "with gzip.open(gene2accession_gz, \"rb\") as f_in, open(gene2accession_file, \"wb\") as f_out:\n",
    "    shutil.copyfileobj(f_in, f_out)\n",
    "os.remove(gene2accession_gz)\n",
    "\n",
    "# 3. Scrape the FTP page for all human.*.protein.faa.gz files\n",
    "base_url = \"https://ftp.ncbi.nlm.nih.gov/refseq/H_sapiens/mRNA_Prot/\"\n",
    "html_page = urllib.request.urlopen(base_url)\n",
    "soup = BeautifulSoup(html_page, \"html.parser\")\n",
    "\n",
    "faa_files = [a['href'] for a in soup.find_all('a', href=True) \n",
    "             if a['href'].startswith(\"human.\") and a['href'].endswith(\".protein.faa.gz\")]\n",
    "\n",
    "print(f\"Found {len(faa_files)} protein FASTA files.\")\n",
    "\n",
    "# 4. Download and unzip each human.*.protein.faa.gz\n",
    "for fname in faa_files:\n",
    "    url = base_url + fname\n",
    "    local_gz = os.path.join(\"protein_dataset\", fname)\n",
    "    local_faa = local_gz[:-3]\n",
    "\n",
    "    print(\"Downloading:\", fname)\n",
    "    r = requests.get(url, stream=True)\n",
    "    with open(local_gz, \"wb\") as f:\n",
    "        shutil.copyfileobj(r.raw, f)\n",
    "\n",
    "    print(\"Unzipping:\", fname)\n",
    "    with gzip.open(local_gz, \"rb\") as f_in, open(local_faa, \"wb\") as f_out:\n",
    "        shutil.copyfileobj(f_in, f_out)\n",
    "\n",
    "    os.remove(local_gz)\n",
    "\n",
    "print(\"✅ All files downloaded and unzipped into protein_dataset/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8f3e442-0cb2-4573-b2ab-9e7fab4149d5",
   "metadata": {},
   "source": [
    "Change the input file path:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0063df8b-cff3-40d3-b18f-fbb0df3ed0cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "Entrez.email = \"anonymous.user@example.com\"\n",
    "\n",
    "# 1. Load your CSV and get unique NM IDs\n",
    "df = pd.read_csv('./benchmark/ClinVarBenchmark_PB_202504.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05050bfc-e8fe-4f91-97cc-42b6f95e2351",
   "metadata": {},
   "source": [
    "Preprocess actual protein sequences with thr refseq_id in benchmark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "363d65ac-dde4-483e-9490-9e446b9c3c60",
   "metadata": {},
   "outputs": [],
   "source": [
    "gene2acc_path = './protein_dataset/gene2accession'\n",
    "\n",
    "target_nm_ids = set(df['ClinVarName_refseq_ids'].dropna().unique())  # Only NM IDs we care about\n",
    "print(f'Total targets = {len(target_nm_ids)}')\n",
    "\n",
    "# 2. Build custom NM→NP mapping (first pass: gene2accession)\n",
    "print(\"Building targeted NM→NP mapping (gene2accession)...\")\n",
    "nm_to_np = {}\n",
    "with open(gene2acc_path) as f:\n",
    "    total_lines = sum(1 for _ in f)\n",
    "\n",
    "with open(gene2acc_path) as f:\n",
    "    for line in tqdm(f, total=total_lines, desc=\"Scanning gene2accession\"):\n",
    "        if line.startswith('#'):\n",
    "            continue\n",
    "        parts = line.strip().split('\\t')\n",
    "        if len(parts) > 5:\n",
    "            nm_id = parts[3]  # NM_XXXX.X\n",
    "            np_id = parts[5]  # NP_XXXX.X\n",
    "            if nm_id in target_nm_ids and np_id.startswith('NP_'):\n",
    "                nm_to_np[nm_id] = np_id\n",
    "\n",
    "# 3. Find missing NM IDs and fetch NP IDs via NCBI API\n",
    "missing_nm_ids = target_nm_ids - set(nm_to_np.keys())\n",
    "print(f\"Found {len(missing_nm_ids)} unmapped NM IDs\")\n",
    "\n",
    "# 4. Fetch sequences for all NP IDs (from local FASTA or NCBI)\n",
    "print(\"Fetching protein sequences...\")\n",
    "\n",
    "def get_sequence(np_id, fasta_files):\n",
    "    \"\"\"Search local FASTA files for NP sequence.\"\"\"\n",
    "    for fasta_file in fasta_files:\n",
    "        with open(fasta_file) as f:\n",
    "            record_id = None\n",
    "            sequence = []\n",
    "            for line in f:\n",
    "                if line.startswith('>'):\n",
    "                    if record_id == np_id:\n",
    "                        return ''.join(sequence)\n",
    "                    record_id = line[1:].split()[0]  # Get first word after >\n",
    "                    sequence = []\n",
    "                elif record_id == np_id:\n",
    "                    sequence.append(line.strip())\n",
    "            if record_id == np_id:\n",
    "                return ''.join(sequence)\n",
    "    return None\n",
    "\n",
    "fasta_files = glob.glob('./protein_dataset/human.*.protein.faa')\n",
    "nm_to_sequence = {}\n",
    "\n",
    "# Try local FASTA files first\n",
    "for nm_id, np_id in tqdm(nm_to_np.items(), desc=\"Processing sequences\"):\n",
    "    sequence = get_sequence(np_id, fasta_files)\n",
    "    if sequence:\n",
    "        nm_to_sequence[nm_id] = sequence\n",
    "    else:\n",
    "        missing_nm_ids.add(nm_id)\n",
    "\n",
    "print(f\"Found {len(missing_nm_ids)} NMs with no sequence.\")\n",
    "\n",
    "\n",
    "def fetch_protein_sequence_from_refseq(transcript_id):\n",
    "    if transcript_id == 'NM_000557.1': # special case\n",
    "        transcript_id = 'NM_000557.5'\n",
    "\n",
    "    handle = Entrez.efetch(db=\"nucleotide\", id=transcript_id, rettype=\"gb\", retmode=\"text\")\n",
    "    record = SeqIO.read(handle, \"genbank\")\n",
    "    handle.close()\n",
    "\n",
    "    for feature in record.features:\n",
    "        if feature.type == \"CDS\" and \"translation\" in feature.qualifiers:\n",
    "            protein_id = feature.qualifiers.get(\"protein_id\", [\"N/A\"])[0]\n",
    "            amino_acid_seq = feature.qualifiers[\"translation\"][0]\n",
    "            return protein_id, amino_acid_seq\n",
    "\n",
    "    return None, None  \n",
    "\n",
    "ext_nm_to_sequence = {}\n",
    "for nm_id in tqdm(missing_nm_ids):\n",
    "    protein_id, aa_seq = fetch_protein_sequence_from_refseq(nm_id)\n",
    "    if aa_seq is not None:\n",
    "        ext_nm_to_sequence[nm_id] = aa_seq\n",
    "\n",
    "nm_to_sequence.update(ext_nm_to_sequence)\n",
    "\n",
    "print(f\"current NP seq = {len(nm_to_sequence)} / {len(target_nm_ids)}\")\n",
    "assert len(nm_to_sequence) == len(target_nm_ids)\n",
    "\n",
    "\n",
    "# 5. Write FASTA (all successful mappings)\n",
    "print(\"Writing FASTA output...\")\n",
    "with open('./protein_dataset/Preprocessed_all_prot.fasta', 'w') as f:\n",
    "    for nm_id, seq in tqdm(nm_to_sequence.items()):\n",
    "        f.write(f\">{nm_id}\\n{seq}\\n\")\n",
    "\n",
    "print(f\"Successfully mapped {len(nm_to_sequence)}/{len(target_nm_ids)} NM IDs\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df2ce525-31cd-4906-ada4-c0ff869f367f",
   "metadata": {},
   "source": [
    "Use https://github.com/ntranoslab/esm-variants to calculate ESM model scores (takes >10 GB disk space)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86e3d2d4-f0e7-41df-9ae4-c973ff10bd7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "!git clone https://github.com/ntranoslab/esm-variants\n",
    "!python ./esm-variants/esm_score_missense_mutations.py --input-fasta-file protein_dataset/Preprocessed_all_prot.fasta --output-csv-file protein_dataset/ESM1b_score.csv --model-name esm1b_t33_650M_UR50S\n",
    "!python ./esm-variants/esm_score_missense_mutations.py --input-fasta-file protein_dataset/Preprocessed_all_prot.fasta --output-csv-file protein_dataset/ESM1v_score.csv --model-name esm1v_t33_650M_UR90S_1\n",
    "!python ./esm-variants/esm_score_missense_mutations.py --input-fasta-file protein_dataset/Preprocessed_all_prot.fasta --output-csv-file protein_dataset/ESM2_score.csv --model-name esm2_t33_650M_UR50D"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38aa95ad-1582-4280-b9c1-c18067567f8c",
   "metadata": {},
   "source": [
    "Merge ESM model scores to 1 csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d2dff8e-10ec-4753-960e-5c78a665fa29",
   "metadata": {},
   "outputs": [],
   "source": [
    "prefix = r'protein_dataset/'\n",
    "reproduced_dict = {'esm1b_t33_650M_UR50S' : {'name' : 'ESM1b',\n",
    "                                             'score_path' : prefix + 'ESM1b_score.csv'\n",
    "                                            },\n",
    "                   'esm1v_t33_650M_UR90S_1' : {'name' : 'ESM1v-1',\n",
    "                                               'score_path' : prefix + 'ESM1v_score.csv'\n",
    "                                              },\n",
    "                   'esm2_t33_650M_UR50D' : {'name' : 'ESM2',\n",
    "                                            'score_path' : prefix + 'ESM2_score.csv'\n",
    "                                           }\n",
    "                  }\n",
    "\n",
    "output_path = r'./protein_dataset/ESM_score.csv'\n",
    "\n",
    "\n",
    "merge_df = None\n",
    "for model_pretrained, model_dict in reproduced_dict.items():\n",
    "    score_df = pd.read_csv(model_dict['score_path'])\n",
    "\n",
    "    if 'esm_score' in score_df.columns:\n",
    "        score_df = score_df.rename(columns={'esm_score': model_dict['name'] + '_score'})\n",
    "\n",
    "    if merge_df is None:\n",
    "        merge_df = score_df\n",
    "    else:\n",
    "        merge_df = pd.merge(merge_df, score_df, on=['seq_id', 'mut_name'], how='inner')\n",
    "\n",
    "# merge_df = reduce(lambda left, right: pd.merge(left, right, on=['seq_id', 'mut_name'], how='inner'), model_df_list)\n",
    "merge_df.to_csv(output_path, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ef3a9f2-b916-4589-8175-c5c495299b10",
   "metadata": {},
   "source": [
    "Calculate the stop_gain scores and filter out scores in the benchmark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7ebaedd-a852-4aaf-b18c-9066359757bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data in chunks if needed\n",
    "all_scores = pd.read_csv('./protein_dataset/ESM_score.csv')\n",
    "benchmark = pd.read_csv('./benchmark/ClinVarBenchmark_PB_202504.csv')\n",
    "\n",
    "# Preprocessing (unchanged)\n",
    "benchmark = benchmark.rename(columns={'#CHROM': 'chrom', 'POS': 'pos', 'INFO': 'label'})\n",
    "benchmark['chrom'] = benchmark['chrom'].astype(str).str.replace('chr', '')\n",
    "benchmark['pos'] = benchmark['pos'].astype(int)\n",
    "benchmark['ID'] = benchmark['ID'].astype(int)\n",
    "# benchmark = benchmark[pd.to_numeric(benchmark['ClinVarName_AAPOS'], errors='coerce').notna()]\n",
    "# benchmark['ClinVarName_AAPOS'] = benchmark['ClinVarName_AAPOS'].astype(int)\n",
    "\n",
    "all_scores[['REF', 'POS', 'ALT']] = all_scores['mut_name'].str.extract(r'([A-Z*])(\\d+)([A-Z*])')\n",
    "all_scores['POS'] = all_scores['POS'].astype(int)\n",
    "\n",
    "# Create merge keys and merge\n",
    "benchmark['merge_key'] = (\n",
    "    benchmark['ClinVarName_refseq_ids'].astype(str) + '_' +\n",
    "    benchmark['ClinVarName_AAREF'].astype(str) +\n",
    "    benchmark['ClinVarName_AAPOS'].apply(lambda x: str(int(x)) if pd.notna(x) else 'nan') +\n",
    "    benchmark['ClinVarName_AAALT'].astype(str)\n",
    ")\n",
    "\n",
    "all_scores['merge_key'] = (\n",
    "    all_scores['seq_id'].astype(str) + '_' +\n",
    "    all_scores['REF'].astype(str) +\n",
    "    all_scores['POS'].apply(lambda x: str(int(x)) if pd.notna(x) else 'nan') +\n",
    "    all_scores['ALT'].astype(str)\n",
    ")\n",
    "\n",
    "models = ['ESM1b', 'ESM1v-1', 'ESM2']\n",
    "result = benchmark.merge(\n",
    "    all_scores[['merge_key'] + [f'{model}_score' for model in models]],\n",
    "    on='merge_key',\n",
    "    how='left'\n",
    ").drop(columns = ['merge_key'])\n",
    "\n",
    "# ========== PROPER DOWNSTREAM SCORING ==========\n",
    "print(\"Finding true downstream worst scores...\")\n",
    "\n",
    "# Group variants by protein for efficient lookup\n",
    "protein_variants = {\n",
    "    seq_id: group[['POS'] + [f'{model}_score' for model in models]]\n",
    "    for seq_id, group in all_scores.groupby('seq_id')\n",
    "}\n",
    "\n",
    "# Process stop codons in chunks\n",
    "stop_mask = result['ClinVarName_AAALT'] == '*'\n",
    "chunk_size = 5000  # Reduce if OOM occurs\n",
    "n_chunks = (stop_mask.sum() // chunk_size) + 1\n",
    "\n",
    "for i in tqdm(range(n_chunks), desc=\"Processing stop codons\"):\n",
    "    chunk = result[stop_mask].iloc[i*chunk_size : (i+1)*chunk_size]\n",
    "    \n",
    "    for idx, row in chunk.iterrows():\n",
    "        refseq = row['ClinVarName_refseq_ids']\n",
    "        stop_pos = row['ClinVarName_AAPOS']\n",
    "        \n",
    "        if refseq not in protein_variants:\n",
    "            continue\n",
    "            \n",
    "        variants = protein_variants[refseq]\n",
    "        downstream = variants[variants['POS'] >= stop_pos]\n",
    "        \n",
    "        if not downstream.empty:\n",
    "            for model in models:\n",
    "                worst_score = downstream[f'{model}_score'].min()\n",
    "                result.at[idx, f'{model}_score'] = worst_score\n",
    "\n",
    "result = result.rename(columns={'chrom' : '#CHROM', 'pos' : 'POS', 'label' : 'INFO'})\n",
    "result = result.iloc[:, [0, 1, 2, -3, -2, -1] + list(range(3, result.shape[1] - 3))]\n",
    "\n",
    "# Save results\n",
    "result.to_csv(\n",
    "    \"./protein_dataset/benchmark_scores.csv\", \n",
    "    index=False\n",
    ")\n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18373021-3b77-4c74-b93c-b4cb918fc3ed",
   "metadata": {},
   "source": [
    "fill in the benchmark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "457a6c23-9495-46a0-bf6f-331a2f0faf24",
   "metadata": {},
   "outputs": [],
   "source": [
    "DNA_scores = pd.read_csv(\"./benchmark/all_scores_v6.csv\")\n",
    "DNA_scores.drop(columns = ['ESM1b_score', 'ESM1v-1_score', 'ESM2_score'], inplace=True)\n",
    "print(DNA_scores.columns.values)\n",
    "\n",
    "protein_scores = pd.read_csv(\"./protein_dataset/benchmark_scores.csv\")\n",
    "protein_scores = protein_scores[['#CHROM', 'POS', 'ID', 'ESM1b_score', 'ESM1v-1_score', 'ESM2_score']]\n",
    "\n",
    "# merge_cols = protein_scores.columns[[0, 1, 2] + list(range(6, protein_scores.shape[1]))].tolist()\n",
    "merge_cols = protein_scores.columns[[0, 1, 2]].tolist()\n",
    "\n",
    "all_scores = pd.merge(DNA_scores,\n",
    "    protein_scores,\n",
    "    on = merge_cols,\n",
    "    how='inner'\n",
    ")\n",
    "\n",
    "print(all_scores.shape[0])\n",
    "print('Any NA?')\n",
    "print(all_scores.isna().any())\n",
    "\n",
    "all_scores.to_csv('./benchmark/all_scores_final.csv', index = False)\n",
    "\n",
    "print('model_merge.py done')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
